#!/usr/bin/env python3
"""
GMB Fast Scraper - VersiÃ³n optimizada para extracciÃ³n rÃ¡pida
Extrae solo: Nombre, TelÃ©fono y Website
Permite mayor volumen con menor riesgo de detecciÃ³n
"""

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
import time
import json
import random
import csv
from datetime import datetime
from tqdm import tqdm
import logging
import argparse

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class GMBFastScraper:
    def __init__(self, headless=False, max_results=30):
        self.driver = None
        self.headless = headless
        self.results = []
        self.max_results_per_location = max_results  # Aumentado a 30 por defecto
        self.user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        ]
        
    def init_driver(self):
        """Inicializar driver con configuraciÃ³n optimizada"""
        options = Options()
        if self.headless:
            options.add_argument('--headless')
        
        # ConfiguraciÃ³n bÃ¡sica anti-detecciÃ³n
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-blink-features=AutomationControlled')
        options.add_argument(f'--user-agent={random.choice(self.user_agents)}')
        
        # Ventana aleatoria
        width = random.randint(1200, 1920)
        height = random.randint(800, 1080)
        options.add_argument(f'--window-size={width},{height}')
        
        # Desactivar imÃ¡genes para mayor velocidad
        prefs = {"profile.managed_default_content_settings.images": 2}
        options.add_experimental_option("prefs", prefs)
        
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)
        
        service = Service(ChromeDriverManager().install())
        self.driver = webdriver.Chrome(service=service, options=options)
        
        # Ocultar webdriver
        self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        
        self.wait = WebDriverWait(self.driver, 15)  # Reducido de 20 a 15
        logger.info("Driver initialized successfully")
        
    def quick_delay(self, min_seconds=0.5, max_seconds=2):
        """Delay mÃ¡s corto para extracciÃ³n rÃ¡pida"""
        time.sleep(random.uniform(min_seconds, max_seconds))
        
    def search_businesses(self, query, location):
        """BÃºsqueda optimizada de negocios"""
        try:
            search_query = f"{query} en {location}, PerÃº"
            url = f"https://www.google.com/maps/search/{search_query.replace(' ', '+')}"
            
            logger.info(f"Searching: {search_query}")
            self.driver.get(url)
            
            # Delay inicial mÃ¡s corto
            self.quick_delay(2, 3)
            
            # Aceptar cookies si aparecen
            try:
                accept_button = self.driver.find_element(By.XPATH, "//button[contains(text(), 'Accept') or contains(text(), 'Aceptar')]")
                accept_button.click()
                self.quick_delay(0.5, 1)
            except:
                pass
            
            # Esperar resultados
            self.quick_delay(1.5, 2.5)
            
            # Buscar elementos de negocio
            business_elements = self.driver.find_elements(By.CSS_SELECTOR, 'a[href*="/maps/place/"]')
            
            if not business_elements:
                logger.warning("No businesses found")
                return []
            
            logger.info(f"Found {len(business_elements)} businesses")
            
            # Scroll mÃ­nimo para cargar mÃ¡s resultados
            if len(business_elements) < self.max_results_per_location:
                try:
                    results_container = self.driver.find_element(By.CSS_SELECTOR, 'div[role="feed"]')
                    for _ in range(2):  # Solo 2 scrolls
                        self.driver.execute_script("arguments[0].scrollTop += 500", results_container)
                        self.quick_delay(0.8, 1.2)
                    
                    # Re-buscar elementos
                    business_elements = self.driver.find_elements(By.CSS_SELECTOR, 'a[href*="/maps/place/"]')
                except:
                    pass
            
            # Limitar resultados
            business_elements = business_elements[:self.max_results_per_location]
            
            businesses = []
            for i, element in enumerate(business_elements):
                try:
                    logger.info(f"Extracting {i+1}/{len(business_elements)}")
                    
                    # Re-encontrar elementos (DOM cambia)
                    current_elements = self.driver.find_elements(By.CSS_SELECTOR, 'a[href*="/maps/place/"]')
                    if i >= len(current_elements):
                        continue
                    
                    business_data = self.extract_basic_info(current_elements[i])
                    if business_data:
                        business_data['location'] = location
                        business_data['search_query'] = query
                        businesses.append(business_data)
                        
                    # Delay mÃ­nimo entre negocios
                    self.quick_delay(0.5, 1)
                    
                except Exception as e:
                    logger.debug(f"Error extracting business {i}: {e}")
                    continue
            
            return businesses
            
        except Exception as e:
            logger.error(f"Error in search: {e}")
            return []
    
    def extract_basic_info(self, element):
        """ExtracciÃ³n minimalista: solo nombre, telÃ©fono y web"""
        try:
            # Click en el elemento
            try:
                self.driver.execute_script("arguments[0].scrollIntoView(true);", element)
                time.sleep(0.3)
                element.click()
            except:
                try:
                    self.driver.execute_script("arguments[0].click();", element)
                except:
                    return None
            
            # Espera mÃ­nima para carga
            self.quick_delay(1.5, 2)
            
            business_info = {
                'name': 'N/A',
                'phone': 'N/A',
                'website': 'N/A',
                'timestamp': datetime.now().isoformat()
            }
            
            # Verificar que estamos en la pÃ¡gina de detalle (no en la lista)
            detail_opened = False
            try:
                # Buscar el botÃ³n de volver que indica que estamos en detalle
                back_selectors = [
                    'button[aria-label*="Back"]',
                    'button[aria-label*="back"]', 
                    'button[aria-label*="AtrÃ¡s"]',
                    'button[aria-label*="Volver"]'
                ]
                for selector in back_selectors:
                    try:
                        self.driver.find_element(By.CSS_SELECTOR, selector)
                        detail_opened = True
                        break
                    except:
                        continue
            except:
                pass
            
            # Si no se abriÃ³ el detalle, devolver None
            if not detail_opened:
                logger.debug("Detail page not opened, skipping")
                return None
            
            # 1. EXTRAER NOMBRE - Mejorado para evitar capturar "Resultados"
            try:
                # Buscar h1 pero excluir "Resultados"
                h1_elements = self.driver.find_elements(By.CSS_SELECTOR, 'h1')
                for h1 in h1_elements:
                    text = h1.text.strip()
                    if text and text not in ['Resultados', 'Results', 'Search results', '']:
                        business_info['name'] = text
                        break
            except:
                pass
            
            # Si aÃºn no tenemos nombre, buscar en otras ubicaciones
            if business_info['name'] == 'N/A':
                try:
                    # Buscar en divs con clase especÃ­fica
                    name_divs = self.driver.find_elements(By.CSS_SELECTOR, 'div[class*="fontHeadlineLarge"]')
                    for div in name_divs:
                        text = div.text.strip()
                        if text and len(text) > 2 and text not in ['Resultados', 'Results']:
                            business_info['name'] = text
                            break
                except:
                    pass
            
            # 2. EXTRAER TELÃ‰FONO (bÃºsqueda directa)
            try:
                # Buscar botones con data-tooltip que contenga "phone" o "telÃ©fono"
                phone_buttons = self.driver.find_elements(By.CSS_SELECTOR, 'button[data-tooltip*="phone"], button[data-tooltip*="Phone"], button[data-tooltip*="telÃ©fono"], button[data-tooltip*="TelÃ©fono"]')
                for btn in phone_buttons:
                    aria_label = btn.get_attribute('aria-label')
                    if aria_label and ('Phone:' in aria_label or 'TelÃ©fono:' in aria_label):
                        phone = aria_label.split(':')[-1].strip()
                        if phone:
                            business_info['phone'] = phone
                            break
            except:
                pass
            
            # Fallback para telÃ©fono: buscar en texto
            if business_info['phone'] == 'N/A':
                try:
                    # Buscar patterns de telÃ©fono en el texto
                    all_text = self.driver.find_element(By.CSS_SELECTOR, 'div[role="main"]').text
                    import re
                    phone_pattern = r'(?:\+51\s?)?(?:\d{1,2}\s?)?\d{3}[\s-]?\d{3}[\s-]?\d{3,4}'
                    phones = re.findall(phone_pattern, all_text)
                    if phones:
                        business_info['phone'] = phones[0].strip()
                except:
                    pass
            
            # 3. EXTRAER WEBSITE (bÃºsqueda rÃ¡pida)
            try:
                # Buscar links con data-tooltip de website
                website_links = self.driver.find_elements(By.CSS_SELECTOR, 'a[data-tooltip*="website"], a[data-tooltip*="Website"], a[data-tooltip*="sitio"], a[data-tooltip*="Sitio"]')
                for link in website_links:
                    href = link.get_attribute('href')
                    if href and not href.startswith('https://www.google.com'):
                        business_info['website'] = href
                        break
            except:
                pass
            
            # Volver a la lista (sin verificar, mÃ¡s rÃ¡pido)
            try:
                back_button = self.driver.find_element(By.CSS_SELECTOR, 'button[aria-label*="Back"], button[aria-label*="back"], button[aria-label*="AtrÃ¡s"]')
                back_button.click()
                self.quick_delay(0.8, 1.2)
            except:
                # Si no hay botÃ³n, intentar navegador back
                self.driver.back()
                self.quick_delay(1, 1.5)
            
            return business_info
            
        except Exception as e:
            logger.debug(f"Error extracting info: {e}")
            # Intentar volver a la lista
            try:
                self.driver.back()
            except:
                pass
            return None
    
    def save_results(self, format='csv'):
        """Guardar resultados en archivo"""
        if not self.results:
            logger.warning("No results to save")
            return
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        if format == 'csv' or format == 'both':
            filename = f"gmb_fast_{timestamp}.csv"
            with open(filename, 'w', newline='', encoding='utf-8') as f:
                writer = csv.DictWriter(f, fieldnames=['name', 'phone', 'website', 'location', 'search_query', 'timestamp'])
                writer.writeheader()
                writer.writerows(self.results)
            logger.info(f"Results saved to {filename}")
        
        if format == 'json' or format == 'both':
            filename = f"gmb_fast_{timestamp}.json"
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(self.results, f, ensure_ascii=False, indent=2)
            logger.info(f"Results saved to {filename}")
        
        # Mostrar resumen
        print(f"\n{'='*50}")
        print(f"EXTRACTION COMPLETE")
        print(f"{'='*50}")
        print(f"Total businesses extracted: {len(self.results)}")
        print(f"Businesses with phone: {sum(1 for r in self.results if r['phone'] != 'N/A')}")
        print(f"Businesses with website: {sum(1 for r in self.results if r['website'] != 'N/A')}")
    
    def run(self, query, locations, format='csv'):
        """Ejecutar scraping completo"""
        self.init_driver()
        
        try:
            for location in tqdm(locations, desc="Processing locations"):
                logger.info(f"Processing: {location}")
                businesses = self.search_businesses(query, location)
                self.results.extend(businesses)
                
                # Delay entre ubicaciones (reducido)
                if location != locations[-1]:
                    self.quick_delay(2, 3)
            
            self.save_results(format)
            
        finally:
            if self.driver:
                self.driver.quit()
                logger.info("Driver closed")

def main():
    parser = argparse.ArgumentParser(description='GMB Fast Scraper - Extract name, phone and website only')
    parser.add_argument('query', help='Search query (e.g., "restaurants", "hotels")')
    parser.add_argument('--locations', nargs='+', default=['Lima'], help='Locations to search')
    parser.add_argument('--max-results', type=int, default=30, help='Max results per location (default: 30)')
    parser.add_argument('--format', choices=['csv', 'json', 'both'], default='csv', help='Output format')
    parser.add_argument('--headless', action='store_true', help='Run in headless mode')
    
    args = parser.parse_args()
    
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘      GMB FAST SCRAPER - PERU ğŸš€       â•‘
    â•‘   Extract: Name, Phone, Website Only   â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    scraper = GMBFastScraper(
        headless=args.headless,
        max_results=args.max_results
    )
    
    scraper.run(
        query=args.query,
        locations=args.locations,
        format=args.format
    )

if __name__ == "__main__":
    main()